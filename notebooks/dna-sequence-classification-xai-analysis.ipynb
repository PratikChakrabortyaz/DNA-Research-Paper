{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1848242,"sourceType":"datasetVersion","datasetId":1099198},{"sourceId":669898,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":507319,"modelId":522044}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install captum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:23:32.855495Z","iopub.execute_input":"2025-12-03T06:23:32.855797Z","iopub.status.idle":"2025-12-03T06:24:40.839341Z","shell.execute_reply.started":"2025-12-03T06:23:32.855772Z","shell.execute_reply":"2025-12-03T06:24:40.838622Z"}},"outputs":[{"name":"stdout","text":"Collecting captum\n  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.7.2)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\nRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->captum)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->captum)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->captum)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->captum)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->captum)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->captum)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->captum)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->captum)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->captum)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->captum)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->captum) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->captum) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->captum) (2024.2.0)\nDownloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, captum\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed captum-0.8.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom captum.attr import GradientShap\nfrom sklearn.metrics import accuracy_score, matthews_corrcoef\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T13:54:16.726671Z","iopub.execute_input":"2025-12-02T13:54:16.727002Z","iopub.status.idle":"2025-12-02T13:54:16.731832Z","shell.execute_reply.started":"2025-12-02T13:54:16.726982Z","shell.execute_reply":"2025-12-02T13:54:16.731014Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\n# -------------------------------------------------------\n# Dataset paths\n# -------------------------------------------------------\nDATASETS = {\n    \"chimpanzee\": \"/kaggle/input/dna-sequence-dataset/chimpanzee.txt\",\n    \"human\": \"/kaggle/input/dna-sequence-dataset/human.txt\",\n    \"dog\": \"/kaggle/input/dna-sequence-dataset/dog.txt\"\n}\n\nMODEL_PATHS = {\n    \"chimpanzee\": \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/LR_best_chimp.pkl\",\n    \"human\":       \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/LR_best_human.pkl\",\n    \"dog\":         \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/LR_best_dog.pkl\"\n}\n\nTARGET_CLASS = 0     # GPCRs\nK = 6                # k-mer size\n\n\n\n# -------------------------------------------------------\n# Load dataset\n# -------------------------------------------------------\ndef load_dataset(name):\n    df = pd.read_csv(DATASETS[name], sep=\"\\t\")\n    df.columns = [\"sequence\", \"class\"]\n    df[\"label\"] = df[\"class\"].astype(\"category\").cat.codes\n    return df\n\n\n# -------------------------------------------------------\n# K-mer extraction\n# -------------------------------------------------------\ndef kmers(seq, k=6):\n    seq = seq.lower()\n    return [seq[i:i+k] for i in range(len(seq)-k+1)]\n\n\n\n# -------------------------------------------------------\n# Extract top-10 LR motifs\n# -------------------------------------------------------\ndef extract_top10_lr_motifs(dataset_name, model_path, k=6, target_class=0):\n\n    # Load dataset\n    df = load_dataset(dataset_name)\n\n    # Build text from kmers\n    df[\"text\"] = df[\"sequence\"].apply(lambda s: \" \".join(kmers(s, k)))\n    texts = df[\"text\"].values\n    labels = df[\"label\"].values\n\n    # Train-test split for vectorizer consistency\n    X_train, X_test, y_train, y_test = train_test_split(\n        texts, labels, test_size=0.2, stratify=labels, random_state=42\n    )\n\n    # Fit vectorizer on whole dataset\n    cv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n    cv.fit(texts)\n    feature_names = np.array(cv.get_feature_names_out())\n\n    # Load LR model\n    LR = joblib.load(model_path)\n\n    # Extract LR coefficients for class 0\n    coef = LR.coef_[target_class]\n\n    # Pick top-10 most positive (most predictive)\n    idx = np.argsort(coef)[::-1][:10]\n    motifs = feature_names[idx].tolist()\n    weights = coef[idx].tolist()\n\n    return motifs, weights\n\n\n\n# -------------------------------------------------------\n# Run Stage-1 analysis for Human, Chimpanzee, Dog\n# -------------------------------------------------------\nresults = {}\n\nfor ds in [\"human\", \"chimpanzee\", \"dog\"]:\n    motifs, weights = extract_top10_lr_motifs(\n        dataset_name=ds,\n        model_path=MODEL_PATHS[ds],\n        k=K,\n        target_class=TARGET_CLASS\n    )\n    \n    results[ds] = {\n        \"motifs\": motifs,\n        \"weights\": weights\n    }\n\n\n\n# -------------------------------------------------------\n# Print individual species top-10 motif lists\n# -------------------------------------------------------\nfor ds in results:\n    print(f\"\\n========================\")\n    print(f\"Top-10 GPCR Motifs → {ds.upper()}\")\n    print(\"========================\")\n    for m, w in zip(results[ds][\"motifs\"], results[ds][\"weights\"]):\n        print(f\"{m}   |   weight={w:.4f}\")\n\n\n\n# -------------------------------------------------------\n# Cross-species table (Human / Chimp / Dog)\n# -------------------------------------------------------\ntop10_table = pd.DataFrame({\n    \"Human\":       results[\"human\"][\"motifs\"],\n    \"Chimpanzee\":  results[\"chimpanzee\"][\"motifs\"],\n    \"Dog\":         results[\"dog\"][\"motifs\"]\n})\n\nprint(\"\\n\\nCROSS-SPECIES TOP-10 MOTIF COMPARISON TABLE:\")\nprint(top10_table)\n\n\n\n# -------------------------------------------------------\n# CONSENSUS MOTIF ANALYSIS (Strict + Majority)\n# -------------------------------------------------------\n\n# Convert motif lists to sets for easy set operations:\nhuman_set = set(results[\"human\"][\"motifs\"])\nchimp_set = set(results[\"chimpanzee\"][\"motifs\"])\ndog_set   = set(results[\"dog\"][\"motifs\"])\n\n# Strict: Appears in ALL 3 species\nstrict_consensus = human_set & chimp_set & dog_set\n\n# Majority: Appears in at least 2 species\nmajority_consensus = (\n    (human_set & chimp_set) |\n    (human_set & dog_set)   |\n    (chimp_set & dog_set)\n)\n\nprint(\"\\n\\n========================\")\nprint(\"STRICT CONSENSUS MOTIFS (appear in ALL 3 species):\")\nprint(\"========================\")\nprint(sorted(list(strict_consensus)) if strict_consensus else \"None\")\n\n\nprint(\"\\n========================\")\nprint(\"MAJORITY CONSENSUS MOTIFS (appear in ≥ 2 species):\")\nprint(\"========================\")\nprint(sorted(list(majority_consensus)) if majority_consensus else \"None\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T03:54:32.584603Z","iopub.execute_input":"2025-12-03T03:54:32.584931Z","iopub.status.idle":"2025-12-03T03:54:40.663670Z","shell.execute_reply.started":"2025-12-03T03:54:32.584907Z","shell.execute_reply":"2025-12-03T03:54:40.662682Z"}},"outputs":[{"name":"stdout","text":"\n========================\nTop-10 GPCR Motifs → HUMAN\n========================\ntcgctg   |   weight=0.2166\ngtcctg   |   weight=0.2010\naacaac   |   weight=0.1985\nagccag   |   weight=0.1940\ngctgtg   |   weight=0.1936\ncagcca   |   weight=0.1933\ntgctct   |   weight=0.1840\ncttctg   |   weight=0.1839\ntgcggc   |   weight=0.1799\nttttca   |   weight=0.1752\n\n========================\nTop-10 GPCR Motifs → CHIMPANZEE\n========================\ngctgtg   |   weight=0.2060\ngcttcc   |   weight=0.2033\ntcatct   |   weight=0.2020\ntcttca   |   weight=0.1904\ncatcat   |   weight=0.1787\ntcgtgg   |   weight=0.1752\nccctgg   |   weight=0.1748\ntgacca   |   weight=0.1717\ncctggg   |   weight=0.1709\ntgcctg   |   weight=0.1679\n\n========================\nTop-10 GPCR Motifs → DOG\n========================\ncctgct   |   weight=0.2274\nctctac   |   weight=0.2260\nacctgg   |   weight=0.2252\nttcatt   |   weight=0.2086\ncctggc   |   weight=0.2061\nctgctc   |   weight=0.2004\ntcttct   |   weight=0.1834\ncctggg   |   weight=0.1779\ntcatct   |   weight=0.1687\nttgttt   |   weight=0.1659\n\n\nCROSS-SPECIES TOP-10 MOTIF COMPARISON TABLE:\n    Human Chimpanzee     Dog\n0  tcgctg     gctgtg  cctgct\n1  gtcctg     gcttcc  ctctac\n2  aacaac     tcatct  acctgg\n3  agccag     tcttca  ttcatt\n4  gctgtg     catcat  cctggc\n5  cagcca     tcgtgg  ctgctc\n6  tgctct     ccctgg  tcttct\n7  cttctg     tgacca  cctggg\n8  tgcggc     cctggg  tcatct\n9  ttttca     tgcctg  ttgttt\n\n\n========================\nSTRICT CONSENSUS MOTIFS (appear in ALL 3 species):\n========================\nNone\n\n========================\nMAJORITY CONSENSUS MOTIFS (appear in ≥ 2 species):\n========================\n['cctggg', 'gctgtg', 'tcatct']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\n# -------------------------------------------------------\n# Dataset + model paths\n# -------------------------------------------------------\nDATASET = \"/kaggle/input/dna-sequence-dataset/human.txt\"\n\nMODEL_PATHS = {\n    \"LR\":  \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/LR_best_human.pkl\",\n    \"RF\":  \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/RF_best_human.pkl\",\n    \"MNB\": \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/MNB_best_human.pkl\"\n}\n\nTARGET_CLASS = 4   # Synthase\nK = 6              # 6-mer features\n\n\n# -------------------------------------------------------\n# Load Human dataset\n# -------------------------------------------------------\ndef load_dataset(path):\n    df = pd.read_csv(path, sep=\"\\t\")\n    df.columns = [\"sequence\", \"class\"]\n    df[\"label\"] = df[\"class\"].astype(\"category\").cat.codes\n    return df\n\n\n# -------------------------------------------------------\n# k-mer extraction\n# -------------------------------------------------------\ndef kmers(seq, k=6):\n    seq = seq.lower()\n    return [seq[i:i+k] for i in range(len(seq)-k+1)]\n\n\n# -------------------------------------------------------\n# Extract top-10 motifs for any ML model\n# -------------------------------------------------------\ndef get_top10(model, feature_names, target_class):\n\n    # Logistic Regression (coef_)\n    if hasattr(model, \"coef_\"):\n        fi = model.coef_[target_class]\n\n    # Multinomial Naive Bayes (feature_log_prob_)\n    elif hasattr(model, \"feature_log_prob_\"):\n        fi = model.feature_log_prob_[target_class]\n\n    # Random Forest (feature_importances_)\n    else:\n        fi = model.feature_importances_\n\n    idx = np.argsort(fi)[::-1][:10]\n    motifs = feature_names[idx].tolist()\n    weights = fi[idx].tolist()\n    return motifs, weights\n\n\n# -------------------------------------------------------\n# Build CountVectorizer and feature list\n# -------------------------------------------------------\ndf = load_dataset(DATASET)\ndf[\"text\"] = df[\"sequence\"].apply(lambda s: \" \".join(kmers(s, K)))\n\ntexts = df[\"text\"].values\nlabels = df[\"label\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    texts, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\ncv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\ncv.fit(texts)\nfeature_names = np.array(cv.get_feature_names_out())\n\n\n# -------------------------------------------------------\n# Extract motifs for LR, RF, MNB\n# -------------------------------------------------------\nresults = {}\n\nfor model_name in MODEL_PATHS:\n    model = joblib.load(MODEL_PATHS[model_name])\n    motifs, weights = get_top10(model, feature_names, TARGET_CLASS)\n\n    results[model_name] = {\n        \"motifs\": motifs,\n        \"weights\": weights\n    }\n\n\n# -------------------------------------------------------\n# Print the results\n# -------------------------------------------------------\nfor m in [\"LR\", \"RF\", \"MNB\"]:\n    print(f\"\\n========================\")\n    print(f\"Top-10 Synthase (Class 4) Motifs → {m}\")\n    print(\"========================\")\n    for motif, w in zip(results[m][\"motifs\"], results[m][\"weights\"]):\n        print(f\"{motif}   |   weight={w:.4f}\")\n\n\n# -------------------------------------------------------\n# Build model comparison table\n# -------------------------------------------------------\ncompare_table = pd.DataFrame({\n    \"LR\":  results[\"LR\"][\"motifs\"],\n    \"RF\":  results[\"RF\"][\"motifs\"],\n    \"MNB\": results[\"MNB\"][\"motifs\"]\n})\n\nprint(\"\\n\\nCROSS-MODEL TOP-10 MOTIF COMPARISON TABLE (Human, Synthase):\")\nprint(compare_table)\n\n\n# -------------------------------------------------------\n# Consensus motif analysis (strict + majority)\n# -------------------------------------------------------\nLR_set  = set(results[\"LR\"][\"motifs\"])\nRF_set  = set(results[\"RF\"][\"motifs\"])\nMNB_set = set(results[\"MNB\"][\"motifs\"])\n\nstrict_consensus = LR_set & RF_set & MNB_set\nmajority_consensus = (\n    (LR_set & RF_set) |\n    (LR_set & MNB_set) |\n    (RF_set & MNB_set)\n)\n\nprint(\"\\n========================\")\nprint(\"STRICT CONSENSUS (in ALL 3 ML models):\")\nprint(\"========================\")\nprint(sorted(list(strict_consensus)) if strict_consensus else \"None\")\n\nprint(\"\\n========================\")\nprint(\"MAJORITY CONSENSUS (in ≥ 2 ML models):\")\nprint(\"========================\")\nprint(sorted(list(majority_consensus)) if majority_consensus else \"None\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T03:59:05.584771Z","iopub.execute_input":"2025-12-03T03:59:05.585106Z","iopub.status.idle":"2025-12-03T03:59:10.599460Z","shell.execute_reply.started":"2025-12-03T03:59:05.585079Z","shell.execute_reply":"2025-12-03T03:59:10.598390Z"}},"outputs":[{"name":"stdout","text":"\n========================\nTop-10 Synthase (Class 4) Motifs → LR\n========================\nctggag   |   weight=0.2636\ntgtccg   |   weight=0.2563\nacattg   |   weight=0.2516\ngtgggg   |   weight=0.2501\nctgtgc   |   weight=0.2411\ngacaga   |   weight=0.2388\nggttct   |   weight=0.2360\ntggggc   |   weight=0.2260\nttggaa   |   weight=0.2254\nggtact   |   weight=0.2212\n\n========================\nTop-10 Synthase (Class 4) Motifs → RF\n========================\ncagcag   |   weight=0.0029\nagcagc   |   weight=0.0020\ntgctgg   |   weight=0.0019\nggcatg   |   weight=0.0018\nctggtg   |   weight=0.0018\nggatgg   |   weight=0.0017\nccagca   |   weight=0.0017\ntggtgt   |   weight=0.0015\ngtgctg   |   weight=0.0015\nctctac   |   weight=0.0015\n\n========================\nTop-10 Synthase (Class 4) Motifs → MNB\n========================\nctggag   |   weight=-6.4281\nctgctg   |   weight=-6.5712\nctgcag   |   weight=-6.6703\ncctgga   |   weight=-6.6816\ntggtgg   |   weight=-6.6930\ntcctgg   |   weight=-6.7029\ntgctgg   |   weight=-6.7112\ngctgga   |   weight=-6.7348\ncagctg   |   weight=-6.7643\ngctgct   |   weight=-6.7875\n\n\nCROSS-MODEL TOP-10 MOTIF COMPARISON TABLE (Human, Synthase):\n       LR      RF     MNB\n0  ctggag  cagcag  ctggag\n1  tgtccg  agcagc  ctgctg\n2  acattg  tgctgg  ctgcag\n3  gtgggg  ggcatg  cctgga\n4  ctgtgc  ctggtg  tggtgg\n5  gacaga  ggatgg  tcctgg\n6  ggttct  ccagca  tgctgg\n7  tggggc  tggtgt  gctgga\n8  ttggaa  gtgctg  cagctg\n9  ggtact  ctctac  gctgct\n\n========================\nSTRICT CONSENSUS (in ALL 3 ML models):\n========================\nNone\n\n========================\nMAJORITY CONSENSUS (in ≥ 2 ML models):\n========================\n['ctggag', 'tgctgg']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\nimport re\n\n# ============================================================\n# Stage 3 Configuration\n# ============================================================\nK = 6   # k-mer size\nRANDOM_STATE = 42\nFUNCTIONAL_GROUPS = list(range(7))  # labels 0–6\n\nMODEL_PATHS = {\n    \"LR\":  \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/LR_best_combined.pkl\",\n    \"RF\":  \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/RF_best_combined.pkl\",\n    \"MNB\": \"/kaggle/input/dna-saved-models/pytorch/default/1/ML Models/ML Models/MNB_best_combined.pkl\"\n}\n\n# ============================================================\n# Step 1 — Load & Combine Dataset\n# ============================================================\nchimp = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/chimpanzee.txt\", sep=\"\\t\").dropna()\nhuman = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/human.txt\", sep=\"\\t\").dropna()\ndog   = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/dog.txt\", sep=\"\\t\").dropna()\n\ncombined = pd.concat([chimp, human, dog], ignore_index=True)\ncombined.columns = [\"sequence\", \"class\"]\ncombined[\"label\"] = combined[\"class\"].astype(\"category\").cat.codes\n\nprint(\"Combined dataset size =\", len(combined))\n\n\n# ============================================================\n# Step 2 — Utility: k-mer conversion\n# ============================================================\ndef kmers(seq, k=6):\n    seq = seq.lower()\n    return [seq[i:i+k] for i in range(len(seq)-k+1)]\n\n\ncombined[\"text\"] = combined[\"sequence\"].apply(lambda s: \" \".join(kmers(s, K)))\n\n\n# ============================================================\n# Step 3 — Vectorizer (fit on full combined dataset)\n# ============================================================\ncv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\ncv.fit(combined[\"text\"].values)\nfeature_names = np.array(cv.get_feature_names_out())\n\nprint(\"Vectorizer vocabulary size =\", len(feature_names))\n\n\n# ============================================================\n# Step 4 — Train-test split (test ONLY for evaluation)\n# ============================================================\nX_train_text, X_test_text, y_train, y_test, seq_train, seq_test = train_test_split(\n    combined[\"text\"].values,\n    combined[\"label\"].values,\n    combined[\"sequence\"].values,\n    test_size=0.2,\n    stratify=combined[\"label\"].values,\n    random_state=RANDOM_STATE\n)\n\nX_test_vec = cv.transform(X_test_text)\n\n\n# ============================================================\n# Step 5 — Model loader\n# ============================================================\nmodels = {\n    name: joblib.load(path)\n    for name, path in MODEL_PATHS.items()\n}\n\nprint(\"Loaded models:\", models.keys())\n\n\n# ============================================================\n# Step 6 — Extract top-10 motifs for each model & functional group\n# ============================================================\ndef get_top10_motifs(model, class_id):\n    if hasattr(model, \"coef_\"):     # LR\n        fi = model.coef_[class_id]\n    elif hasattr(model, \"feature_log_prob_\"):  # MNB\n        fi = model.feature_log_prob_[class_id]\n    else:                           # RF\n        fi = model.feature_importances_\n\n    idx = np.argsort(fi)[::-1][:10]\n    return feature_names[idx].tolist(), fi[idx].tolist()\n\n\n# ============================================================\n# Step 7 — Masking function (NNNNNN replacement)\n# ============================================================\ndef mask_motifs(sequence, motifs, k=6):\n    seq = sequence.lower()\n    for m in motifs:\n        seq = re.sub(m, \"N\" * k, seq)\n    return seq\n\n\n# ============================================================\n# Step 8 — Evaluation helper\n# ============================================================\ndef evaluate(model, X_vec, y_true):\n    y_pred = model.predict(X_vec)\n    return {\n        \"acc\": accuracy_score(y_true, y_pred),\n        \"f1\": f1_score(y_true, y_pred, average=\"macro\"),\n        \"mcc\": matthews_corrcoef(y_true, y_pred)\n    }\n\n\n# ============================================================\n# Step 9 — Stability metrics (Jaccard, intersection, % overlap)\n# ============================================================\ndef stability_metrics(setA, setB):\n    inter = len(setA & setB)\n    union = len(setA | setB)\n    jaccard = inter / union if union > 0 else 0\n    percent = inter / 10\n    return inter, jaccard, percent\n\n\n# ============================================================\n# MAIN STAGE 3 LOOP\n# ============================================================\nfor fg in FUNCTIONAL_GROUPS:\n    print(\"\\n\\n\" + \"=\"*70)\n    print(f\"FUNCTIONAL GROUP {fg} — ANALYSIS\")\n    print(\"=\"*70)\n\n    # ---------------------------------------------------\n    # A. Extract motifs for LR, RF, MNB\n    # ---------------------------------------------------\n    top10 = {}\n    for model_name, model in models.items():\n        motifs, weights = get_top10_motifs(model, fg)\n        top10[model_name] = motifs\n\n    print(\"\\nTop-10 motifs per model:\")\n    print(pd.DataFrame(top10))\n\n\n    # ---------------------------------------------------\n    # B. Stability metrics\n    # ---------------------------------------------------\n    LR_set  = set(top10[\"LR\"])\n    RF_set  = set(top10[\"RF\"])\n    MNB_set = set(top10[\"MNB\"])\n\n    stability = {\n        \"LR-RF\":  stability_metrics(LR_set, RF_set),\n        \"LR-MNB\": stability_metrics(LR_set, MNB_set),\n        \"RF-MNB\": stability_metrics(RF_set, MNB_set)\n    }\n\n    print(\"\\nStability (intersection, jaccard, percent overlap):\")\n    for pair, (inter, jac, pct) in stability.items():\n        print(f\"{pair}: inter={inter},  jaccard={jac:.3f},  overlap%={pct*100:.1f}\")\n\n\n    # ---------------------------------------------------\n    # C. Baseline evaluation\n    # ---------------------------------------------------\n    print(\"\\nEvaluating baseline performance...\")\n    baseline = {\n        name: evaluate(model, X_test_vec, y_test)\n        for name, model in models.items()\n    }\n    print(pd.DataFrame(baseline).T)\n\n\n    # ---------------------------------------------------\n    # D. Masking test set for each model\n    # ---------------------------------------------------\n    fidelity_results = {}\n\n    for model_name, model in models.items():\n\n        print(f\"\\nMasking for model = {model_name}\")\n\n        # Mask sequences using that model's motifs for this FG\n        masked_sequences = [mask_motifs(seq, top10[model_name], k=K) for seq in seq_test]\n\n        # Convert to k-mer text\n        masked_texts = [\" \".join(kmers(seq, K)) for seq in masked_sequences]\n        masked_vec = cv.transform(masked_texts)\n\n        # Re-evaluate after masking\n        masked_eval = evaluate(model, masked_vec, y_test)\n\n        # Fidelity drop\n        fidelity_results[model_name] = {\n            \"acc_drop\": baseline[model_name][\"acc\"] - masked_eval[\"acc\"],\n            \"f1_drop\":  baseline[model_name][\"f1\"] - masked_eval[\"f1\"],\n            \"mcc_drop\": baseline[model_name][\"mcc\"] - masked_eval[\"mcc\"]\n        }\n\n    print(\"\\nFidelity drops after masking:\")\n    print(pd.DataFrame(fidelity_results).T)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:09:26.375271Z","iopub.execute_input":"2025-12-03T04:09:26.376163Z","iopub.status.idle":"2025-12-03T04:10:26.106979Z","shell.execute_reply.started":"2025-12-03T04:09:26.376128Z","shell.execute_reply":"2025-12-03T04:10:26.105956Z"}},"outputs":[{"name":"stdout","text":"Combined dataset size = 6882\nVectorizer vocabulary size = 4556\nLoaded models: dict_keys(['LR', 'RF', 'MNB'])\n\n\n======================================================================\nFUNCTIONAL GROUP 0 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  ggccac  tgctgg  ctgctg\n1  tcgctg  cagcag  tgctgg\n2  atgctc  ctgctg  tcctgg\n3  tgctct  ctggtg  tgctgc\n4  gtcgct  cctgct  gctgct\n5  tattgt  ccagca  cctgct\n6  cagtcg  agcagc  cctgga\n7  cgctgc  cctggt  cttcct\n8  agagag  accagc  cctggg\n9  gggctg  ggcatg  ctgcag\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=3,  jaccard=0.176,  overlap%=30.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.003631  0.003687  0.004460\nRF   0.014524  0.016084  0.017216\nMNB  0.052288  0.073003  0.064799\n\n\n======================================================================\nFUNCTIONAL GROUP 1 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  nacgcc  tgctgg  ctgctg\n1  acgcct  cagcag  ctggag\n2  ggcatg  ctgctg  gctgga\n3  gcgagg  ctggtg  tgctgg\n4  ggatgg  cctgct  ctgcag\n5  gggacc  ccagca  gctgct\n6  cgcctg  agcagc  gaggag\n7  cctggt  cctggt  ggctgc\n8  gaaata  accagc  cagccc\n9  gaactg  ggcatg  ctggtg\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=2,  jaccard=0.111,  overlap%=20.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=3,  jaccard=0.176,  overlap%=30.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.015251  0.015193  0.018596\nRF   0.014524  0.016084  0.017216\nMNB  0.076253  0.087331  0.086285\n\n\n======================================================================\nFUNCTIONAL GROUP 2 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  cccaag  tgctgg  agaaga\n1  gagatc  cagcag  ctgcag\n2  ccgaga  ctgctg  gaagaa\n3  ccactg  ctggtg  ctggag\n4  tttctg  cctgct  ctggcc\n5  gggagg  ccagca  cagcag\n6  gcccaa  agcagc  tggaga\n7  acacct  cctggt  cctgga\n8  tggagt  accagc  tgaaga\n9  ttgtca  ggcatg  acatca\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=1,  jaccard=0.053,  overlap%=10.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.009441  0.012514  0.011631\nRF   0.014524  0.016084  0.017216\nMNB  0.108206  0.117423  0.117879\n\n\n======================================================================\nFUNCTIONAL GROUP 3 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  tgggat  tgctgg  ctggag\n1  caagat  cagcag  tggaga\n2  atgccc  ctgctg  ctgtgg\n3  ggggag  ctggtg  gaagaa\n4  gtcagg  cctgct  aagaag\n5  tgtcag  ccagca  tgaaga\n6  aacata  agcagc  ggagaa\n7  ccttta  cctggt  tggctg\n8  cacaca  accagc  cctgga\n9  tttaag  ggcatg  ctgctg\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=1,  jaccard=0.053,  overlap%=10.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.008715  0.009818  0.010750\nRF   0.014524  0.016084  0.017216\nMNB  0.061728  0.083312  0.074475\n\n\n======================================================================\nFUNCTIONAL GROUP 4 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  tgtccg  tgctgg  ctggag\n1  ggttct  cagcag  ctgctg\n2  gtgatt  ctgctg  cctgga\n3  ggtact  ctggtg  ctgcag\n4  ctgtgc  cctgct  tgctgg\n5  ctggag  ccagca  gctgga\n6  gtgaga  agcagc  tcctgg\n7  gggtgg  cctggt  cagctg\n8  agtggg  accagc  tggtgg\n9  ttccgc  ggcatg  gctgct\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=1,  jaccard=0.053,  overlap%=10.0\nRF-MNB: inter=2,  jaccard=0.111,  overlap%=20.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.007988  0.007348  0.009771\nRF   0.014524  0.016084  0.017216\nMNB  0.050835  0.074989  0.063091\n\n\n======================================================================\nFUNCTIONAL GROUP 5 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  tggact  tgctgg  ctgctg\n1  ttcaca  cagcag  agaaga\n2  catcct  ctgctg  gaagaa\n3  acgctg  ctggtg  gaggag\n4  ctgatg  cctgct  tgctgg\n5  catggt  ccagca  ggagga\n6  acctgc  agcagc  aagaag\n7  cgtgga  cctggt  ctggag\n8  cccaag  accagc  tgctgc\n9  gccact  ggcatg  gctgct\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=2,  jaccard=0.111,  overlap%=20.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.006536  0.014382  0.008055\nRF   0.014524  0.016084  0.017216\nMNB  0.066812  0.078025  0.076761\n\n\n======================================================================\nFUNCTIONAL GROUP 6 — ANALYSIS\n======================================================================\n\nTop-10 motifs per model:\n       LR      RF     MNB\n0  caagct  tgctgg  cagcag\n1  aggcgg  cagcag  agcagc\n2  caacca  ctgctg  agaaga\n3  agctca  ctggtg  gcagca\n4  ccccgg  cctgct  gaagaa\n5  cacaga  ccagca  aagaag\n6  actcct  agcagc  gaggag\n7  gaaact  cctggt  ggagga\n8  tccgga  accagc  ccagca\n9  atgaag  ggcatg  aagaaa\n\nStability (intersection, jaccard, percent overlap):\nLR-RF: inter=0,  jaccard=0.000,  overlap%=0.0\nLR-MNB: inter=0,  jaccard=0.000,  overlap%=0.0\nRF-MNB: inter=3,  jaccard=0.176,  overlap%=30.0\n\nEvaluating baseline performance...\n          acc        f1       mcc\nLR   0.938272  0.939952  0.924467\nRF   0.904139  0.910224  0.885401\nMNB  0.660857  0.656981  0.601481\n\nMasking for model = LR\n\nMasking for model = RF\n\nMasking for model = MNB\n\nFidelity drops after masking:\n     acc_drop   f1_drop  mcc_drop\nLR   0.016703  0.014269  0.019825\nRF   0.014524  0.016084  0.017216\nMNB  0.108932  0.107110  0.115696\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom captum.attr import IntegratedGradients\n\n\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ============================================================\n# PARAMS\n# ============================================================\nK = 6\nMAX_LEN = 300\nBATCH = 32\nFG = 0   # functional group to analyze (GPCR)\n\nDATASETS = {\n    \"chimpanzee\": \"/kaggle/input/dna-sequence-dataset/chimpanzee.txt\",\n    \"human\":      \"/kaggle/input/dna-sequence-dataset/human.txt\",\n    \"dog\":        \"/kaggle/input/dna-sequence-dataset/dog.txt\"\n}\n\n# CNN configs from your logs\nCNN_CONFIG = {\n    \"chimpanzee\": {\"embed_dim\":128, \"num_filters\":256, \"kernel_sizes\":(5,7,9)},\n    \"human\":      {\"embed_dim\":128, \"num_filters\":256, \"kernel_sizes\":(5,7,9)},\n    \"dog\":        {\"embed_dim\":256, \"num_filters\":256, \"kernel_sizes\":(3,5,7)}\n}\n\nMODEL_PATH = {\n    \"chimpanzee\": \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/chimpanzee_kmer_CNN.pt\",\n    \"human\":      \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN.pt\",\n    \"dog\":        \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/dog_kmer_CNN.pt\"\n}\n\n# ============================================================\n# Utility functions (from your training pipeline)\n# ============================================================\ndef kmers(seq, k=6):\n    return [seq[i:i+k].lower() for i in range(len(seq)-k+1)]\n\ndef build_vocab(seqs):\n    all_k = []\n    for s in seqs:\n        all_k.extend(kmers(s, K))\n    return {k:i+1 for i,(k,_) in enumerate(Counter(all_k).most_common())}\n\ndef encode_kmer(seq, vocab):\n    return [vocab[k] for k in kmers(seq, K) if k in vocab]\n\ndef pad_kmer(seqs):\n    out = np.zeros((len(seqs), MAX_LEN), dtype=np.int64)\n    for i, s in enumerate(seqs):\n        out[i, :len(s[:MAX_LEN])] = s[:MAX_LEN]\n    return out\n\nclass KmerDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.long)\n        self.y = torch.tensor(y, dtype=torch.long)\n    def __len__(self): return len(self.X)\n    def __getitem__(self, i): return self.X[i], self.y[i]\n\n# ============================================================\n# CNN MODEL (exact match to training)\n# ============================================================\nclass CNN(nn.Module):\n    def __init__(self, vocab_size, num_classes, embed_dim, num_filters, kernel_sizes, dropout=0.4):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.convs = nn.ModuleList(\n            [nn.Conv1d(embed_dim, num_filters, k, padding=k//2) for k in kernel_sizes]\n        )\n        self.drop = nn.Dropout(dropout)\n        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n\n    def forward(self, x):\n        x = self.embed(x)               # (B,T,E)\n        x = x.transpose(1,2)            # (B,E,T)\n        h = [F.max_pool1d(F.relu(c(x)), x.shape[2]).squeeze(2)\n             for c in self.convs]\n        return self.fc(self.drop(torch.cat(h, 1)))\n\n# ============================================================\n# WRAPPER for IG (IG operates on embedded vectors, not indices)\n# ============================================================\nclass CNN_Embedded(nn.Module):\n    def __init__(self, cnn_model):\n        super().__init__()\n        self.cnn = cnn_model\n\n    def forward(self, embedded_x):\n        # embedded_x shape = (B,T,E)\n        x = embedded_x.transpose(1,2)  # (B,E,T)\n        h = [F.max_pool1d(F.relu(conv(x)), x.shape[2]).squeeze(2)\n             for conv in self.cnn.convs]\n        out = self.cnn.fc(self.cnn.drop(torch.cat(h,1)))\n        return out\n\n# ============================================================\n# Load dataset\n# ============================================================\ndef load_dataset(name):\n    df = pd.read_csv(DATASETS[name], sep=\"\\t\")\n    df.columns = [\"sequence\", \"class\"]\n    df[\"label\"] = df[\"class\"].astype(\"category\").cat.codes\n    return df\n\n# ============================================================\n# Integrated Gradients → top10 motifs per dataset\n# ============================================================\ndef get_top10_IG_for_dataset(ds_name):\n\n    print(\"\\n\" + \"=\"*70)\n    print(f\"DATASET: {ds_name.upper()} — CNN IG FOR FG={FG}\")\n    print(\"=\"*70)\n\n    # -----------------------------\n    # Load dataset\n    # -----------------------------\n    df = load_dataset(ds_name)\n    X_raw = df[\"sequence\"].values\n    y = df[\"label\"].values\n    NUM_CLASSES = len(np.unique(y))\n\n    # -----------------------------\n    # Build vocab per dataset\n    # -----------------------------\n    vocab = build_vocab(X_raw)\n    vocab_inv = {v:k for k,v in vocab.items()}\n\n    # -----------------------------\n    # Encode + pad\n    # -----------------------------\n    X_enc = [encode_kmer(s, vocab) for s in X_raw]\n    X_pad = pad_kmer(X_enc)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_pad, y, test_size=0.2, stratify=y, random_state=42\n    )\n\n    # -----------------------------\n    # Load trained CNN with correct config\n    # -----------------------------\n    cfg = CNN_CONFIG[ds_name]\n\n    cnn = CNN(\n        vocab_size=len(vocab)+1,\n        num_classes=NUM_CLASSES,\n        embed_dim=cfg[\"embed_dim\"],\n        num_filters=cfg[\"num_filters\"],\n        kernel_sizes=cfg[\"kernel_sizes\"]\n    ).to(DEVICE)\n\n    cnn.load_state_dict(torch.load(MODEL_PATH[ds_name], map_location=DEVICE))\n    cnn.eval()\n\n    wrap = CNN_Embedded(cnn).to(DEVICE)\n    ig = IntegratedGradients(wrap)\n\n    # -----------------------------\n    # Run IG only on FG samples\n    # -----------------------------\n    idx_fg = np.where(y_test == FG)[0]\n    print(f\"Test samples for FG={FG}: {len(idx_fg)}\")\n\n    total_attr = Counter()\n\n    for idx in idx_fg:\n        x = torch.tensor(X_test[idx], dtype=torch.long).unsqueeze(0).to(DEVICE)\n\n        # embedded input\n        emb = cnn.embed(x)                      # (1,T,E)\n        baseline = torch.zeros_like(emb)        # baseline = zero embedding\n\n        # IG attribution\n        attr_emb, _ = ig.attribute(\n            emb,\n            baselines=baseline,\n            target=FG,\n            n_steps=50,\n            return_convergence_delta=True\n        )\n\n        # reduce embedding dimension → token-level attribution\n        token_scores = attr_emb.sum(dim=2).squeeze(0).detach().cpu().numpy()\n\n        # accumulate per token-id\n        for pos, score in enumerate(token_scores):\n            token_id = int(X_test[idx][pos])\n            if token_id != 0:\n                total_attr[token_id] += float(score)\n\n    # -----------------------------\n    # Convert token IDs → k-mers\n    # -----------------------------\n    kmer_attr = {}\n    for token_id, score in total_attr.items():\n        if token_id in vocab_inv and score > 0:\n            kmer_attr[vocab_inv[token_id]] = score\n\n    # -----------------------------\n    # Top-10 motifs\n    # -----------------------------\n    top10 = sorted(kmer_attr.items(), key=lambda x: x[1], reverse=True)[:10]\n\n    motifs = [m for m,_ in top10]\n    weights = [w for _,w in top10]\n\n    return motifs, weights\n\n# ============================================================\n# RUN IG FOR ALL THREE DATASETS\n# ============================================================\nresults = {}\n\nfor ds in [\"human\", \"chimpanzee\", \"dog\"]:\n    motifs, weights = get_top10_IG_for_dataset(ds)\n    results[ds] = {\"motifs\": motifs, \"weights\": weights}\n\n# ============================================================\n# PRINT INDIVIDUAL DATASET RESULTS\n# ============================================================\nfor ds in results:\n    print(\"\\n========================\")\n    print(f\"Top-10 IG Motifs → {ds.upper()}\")\n    print(\"========================\")\n    for m,w in zip(results[ds][\"motifs\"], results[ds][\"weights\"]):\n        print(f\"{m}   |   score={w:.4f}\")\n\n# ============================================================\n# CROSS-SPECIES TABLE\n# ============================================================\ntop10_table = pd.DataFrame({\n    \"Human\": results[\"human\"][\"motifs\"],\n    \"Chimpanzee\": results[\"chimpanzee\"][\"motifs\"],\n    \"Dog\": results[\"dog\"][\"motifs\"]\n})\n\nprint(\"\\n\\nCROSS-SPECIES TOP-10 IG MOTIF COMPARISON TABLE:\")\nprint(top10_table)\n\n# ============================================================\n# CONSENSUS ANALYSIS\n# ============================================================\nh = set(results[\"human\"][\"motifs\"])\nc = set(results[\"chimpanzee\"][\"motifs\"])\nd = set(results[\"dog\"][\"motifs\"])\n\nstrict_consensus = h & c & d\nmajority_consensus = (h & c) | (h & d) | (c & d)\n\nprint(\"\\n\\n========================\")\nprint(\"STRICT CONSENSUS MOTIFS (appear in ALL 3 species):\")\nprint(\"========================\")\nprint(list(strict_consensus) if strict_consensus else \"None\")\n\nprint(\"\\n========================\")\nprint(\"MAJORITY CONSENSUS MOTIFS (appear in ≥2 species):\")\nprint(\"========================\")\nprint(list(majority_consensus) if majority_consensus else \"None\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:36:07.710657Z","iopub.execute_input":"2025-12-03T06:36:07.711344Z","iopub.status.idle":"2025-12-03T06:36:18.190358Z","shell.execute_reply.started":"2025-12-03T06:36:07.711316Z","shell.execute_reply":"2025-12-03T06:36:18.189565Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nDATASET: HUMAN — CNN IG FOR FG=0\n======================================================================\nTest samples for FG=0: 106\n\n======================================================================\nDATASET: CHIMPANZEE — CNN IG FOR FG=0\n======================================================================\nTest samples for FG=0: 47\n\n======================================================================\nDATASET: DOG — CNN IG FOR FG=0\n======================================================================\nTest samples for FG=0: 26\n\n========================\nTop-10 IG Motifs → HUMAN\n========================\ntgttcc   |   score=21.4962\ncctgct   |   score=19.4643\nctgctc   |   score=19.3442\nctcttc   |   score=19.3343\ntgctct   |   score=18.6367\nttcctg   |   score=18.2247\ngttcct   |   score=16.3187\ncttctg   |   score=16.1633\nctgctg   |   score=14.4151\ntcttct   |   score=12.9497\n\n========================\nTop-10 IG Motifs → CHIMPANZEE\n========================\ncctgct   |   score=10.4112\nctgctc   |   score=10.2236\ntgctct   |   score=6.7357\nctcttc   |   score=5.6141\nccctgc   |   score=5.4651\nctcctg   |   score=4.5408\ntgctcc   |   score=4.3208\nctgctg   |   score=4.1764\ngctcct   |   score=3.7282\nctggcc   |   score=3.5170\n\n========================\nTop-10 IG Motifs → DOG\n========================\ngctgct   |   score=3.7453\nctgctc   |   score=3.4347\ntcctgg   |   score=3.0909\ntgctgc   |   score=3.0881\ncctgct   |   score=2.3990\nctgctg   |   score=2.3687\ncttcct   |   score=2.3247\nctgcct   |   score=2.2193\ntgcctc   |   score=2.2141\nttcctg   |   score=2.0479\n\n\nCROSS-SPECIES TOP-10 IG MOTIF COMPARISON TABLE:\n    Human Chimpanzee     Dog\n0  tgttcc     cctgct  gctgct\n1  cctgct     ctgctc  ctgctc\n2  ctgctc     tgctct  tcctgg\n3  ctcttc     ctcttc  tgctgc\n4  tgctct     ccctgc  cctgct\n5  ttcctg     ctcctg  ctgctg\n6  gttcct     tgctcc  cttcct\n7  cttctg     ctgctg  ctgcct\n8  ctgctg     gctcct  tgcctc\n9  tcttct     ctggcc  ttcctg\n\n\n========================\nSTRICT CONSENSUS MOTIFS (appear in ALL 3 species):\n========================\n['ctgctg', 'ctgctc', 'cctgct']\n\n========================\nMAJORITY CONSENSUS MOTIFS (appear in ≥2 species):\n========================\n['tgctct', 'ctgctc', 'ctgctg', 'cctgct', 'ttcctg', 'ctcttc']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom captum.attr import IntegratedGradients\nimport torch\ntorch.backends.cudnn.enabled = False\ntorch.backends.cudnn.deterministic = False\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ============================================================\n# PARAMS\n# ============================================================\nK = 6\nMAX_LEN = 300\nBATCH = 32\nFG = 6   # Transcription Factor\n\nDATASET = \"/kaggle/input/dna-sequence-dataset/human.txt\"\n\n# ============================================================\n# DL CONFIGS FOR HUMAN DATASET (from your logs)\n# ============================================================\nCNN_CFG =       {\"embed_dim\":128, \"num_filters\":256, \"kernel_sizes\":(5,7,9)}\nATTN_CFG =      {\"embed_dim\":256, \"conv_filters\":256, \"conv_kernel\":15, \"n_heads\":4}\nBI_LSTM_CFG =   {\"embed_dim\":128, \"conv_filters\":256, \"lstm_hidden\":256}\n\nMODEL_PATHS = {\n    \"CNN\":          \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN.pt\",\n    \"CNN-Attn\":     \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN-Attention.pt\",\n    \"CNN-BiLSTM\":   \"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN-BiLSTM.pt\"\n}\n\n# ============================================================\n# Utility functions (same as training)\n# ============================================================\ndef kmers(seq, k=6):\n    return [seq[i:i+k].lower() for i in range(len(seq)-k+1)]\n\ndef build_vocab(seqs):\n    all_k = []\n    for s in seqs:\n        all_k.extend(kmers(s, K))\n    return {k:i+1 for i,(k,_) in enumerate(Counter(all_k).most_common())}\n\ndef encode_kmer(seq, vocab):\n    return [vocab[k] for k in kmers(seq, K) if k in vocab]\n\ndef pad_kmer(seqs):\n    out = np.zeros((len(seqs), MAX_LEN), dtype=np.int64)\n    for i,s in enumerate(seqs):\n        out[i,:len(s[:MAX_LEN])] = s[:MAX_LEN]\n    return out\n\nclass KmerDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.long)\n        self.y = torch.tensor(y, dtype=torch.long)\n    def __len__(self): return len(self.X)\n    def __getitem__(self, i): return self.X[i], self.y[i]\n\n# ============================================================\n# Three DL models for analysis\n# ============================================================\nclass CNN(nn.Module):\n    def __init__(self, vocab_size, num_classes, embed_dim, num_filters, kernel_sizes, dropout=0.4):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, k, padding=k//2) for k in kernel_sizes])\n        self.drop = nn.Dropout(dropout)\n        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n\n    def forward(self, x):\n        x = self.embed(x)\n        x = x.transpose(1,2)\n        h = [F.max_pool1d(F.relu(c(x)), x.shape[2]).squeeze(2) for c in self.convs]\n        return self.fc(self.drop(torch.cat(h,1)))\n\nclass CNNAttention(nn.Module):\n    def __init__(self,vocab_size,num_classes,embed_dim,conv_filters,conv_kernel,n_heads,dropout=0.4):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(embed_dim,conv_filters,conv_kernel,padding=conv_kernel//2)\n        self.proj = nn.Linear(conv_filters,embed_dim)\n        self.attn = nn.MultiheadAttention(embed_dim,n_heads,batch_first=True)\n        self.drop = nn.Dropout(dropout)\n        self.fc = nn.Linear(embed_dim,num_classes)\n\n    def forward(self,x):\n        x = self.embed(x)\n        x = F.relu(self.conv(x.transpose(1,2))).transpose(1,2)\n        x = self.proj(x)\n        a,_ = self.attn(x,x,x)\n        return self.fc(self.drop(a.mean(1)))\n\nclass CNNBiLSTM(nn.Module):\n    def __init__(self,vocab_size,num_classes,embed_dim,conv_filters,lstm_hidden,dropout=0.3):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(embed_dim,conv_filters,7,padding=3)\n        self.lstm = nn.LSTM(conv_filters,lstm_hidden,batch_first=True,bidirectional=True)\n        self.drop = nn.Dropout(dropout)\n        self.fc = nn.Linear(lstm_hidden * 2,num_classes)\n\n    def forward(self,x):\n        x = self.embed(x)\n        x = F.relu(self.conv(x.transpose(1,2))).transpose(1,2)\n        h,_ = self.lstm(x)\n        h,_ = torch.max(h,1)\n        return self.fc(self.drop(h))\n\n# ============================================================\n# Wrapper for IG (operates on embedded tensors)\n# ============================================================\nclass WrappedModel(nn.Module):\n    def __init__(self, base_model, model_type):\n        super().__init__()\n        self.base = base_model\n        self.model_type = model_type\n\n    def forward(self, embedded_x):\n        if self.model_type == \"CNN\":\n            x = embedded_x.transpose(1,2)\n            h = [F.max_pool1d(F.relu(conv(x)), x.shape[2]).squeeze(2) \n                 for conv in self.base.convs]\n            return self.base.fc(self.base.drop(torch.cat(h,1)))\n\n        elif self.model_type == \"CNN-Attn\":\n            x = embedded_x.transpose(1,2)\n            x = F.relu(self.base.conv(x)).transpose(1,2)\n            x = self.base.proj(x)\n            a,_ = self.base.attn(x,x,x)\n            return self.base.fc(self.base.drop(a.mean(1)))\n\n        else:  # CNN-BiLSTM\n            x = embedded_x.transpose(1,2)\n            x = F.relu(self.base.conv(x)).transpose(1,2)\n            h,_ = self.base.lstm(x)\n            h,_ = torch.max(h,1)\n            return self.base.fc(self.base.drop(h))\n\n# ============================================================\n# IG extraction for Transcription Factor (FG=6)\n# ============================================================\ndef get_top10_IG(model_name, cfg, model_path):\n\n    print(f\"\\n\\n============================\")\n    print(f\"MODEL: {model_name}\")\n    print(\"============================\")\n\n    # -------------------\n    # Load dataset\n    # -------------------\n    df = pd.read_csv(DATASET, sep=\"\\t\")\n    df.columns = [\"sequence\", \"class\"]\n    df[\"label\"] = df[\"class\"].astype(\"category\").cat.codes\n    X_raw = df[\"sequence\"].values\n    y = df[\"label\"].values\n    NUM_CLASSES = len(np.unique(y))\n\n    # -------------------\n    # Build vocab\n    # -------------------\n    vocab = build_vocab(X_raw)\n    vocab_inv = {v:k for k,v in vocab.items()}\n\n    X_enc = [encode_kmer(s,vocab) for s in X_raw]\n    X_pad = pad_kmer(X_enc)\n\n    X_train,X_test,y_train,y_test = train_test_split(\n        X_pad,y,test_size=0.2,stratify=y,random_state=42\n    )\n\n    # -------------------\n    # Load correct model\n    # -------------------\n    if model_name == \"CNN\":\n        base_model = CNN(len(vocab)+1, NUM_CLASSES, **cfg).to(DEVICE)\n\n    elif model_name == \"CNN-Attn\":\n        base_model = CNNAttention(len(vocab)+1, NUM_CLASSES, **cfg).to(DEVICE)\n\n    else:\n        base_model = CNNBiLSTM(len(vocab)+1, NUM_CLASSES, **cfg).to(DEVICE)\n\n    base_model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n    base_model.eval()\n\n    # -------------------\n    # IG wrapper\n    # -------------------\n    wrap = WrappedModel(base_model, model_name).to(DEVICE)\n    ig = IntegratedGradients(wrap)\n\n    # -------------------\n    # Use only TF class samples\n    # -------------------\n    idx_fg = np.where(y_test == FG)[0]\n    print(f\"TF samples in test set: {len(idx_fg)}\")\n\n    total_attr = Counter()\n\n    # -------------------\n    # IG loop\n    # -------------------\n    for idx in idx_fg:\n        x = torch.tensor(X_test[idx], dtype=torch.long).unsqueeze(0).to(DEVICE)\n\n        embedded = base_model.embed(x)\n        baseline = torch.zeros_like(embedded)\n\n        attr_emb,_ = ig.attribute(\n            embedded,\n            baselines=baseline,\n            target=FG,\n            n_steps=40,\n            return_convergence_delta=True\n        )\n\n        scores = attr_emb.sum(dim=2).squeeze(0).detach().cpu().numpy()\n\n        for pos,score in enumerate(scores):\n            token_id = int(X_test[idx][pos])\n            if token_id != 0:\n                total_attr[token_id] += float(score)\n\n    # -------------------\n    # Map back to k-mers\n    # -------------------\n    kmer_attr = {vocab_inv[t]:score for t,score in total_attr.items()\n                 if t in vocab_inv and score > 0}\n\n    top10 = sorted(kmer_attr.items(), key=lambda x: x[1], reverse=True)[:10]\n\n    motifs = [m for m,_ in top10]\n    weights = [w for _,w in top10]\n\n    return motifs, weights\n\n# ============================================================\n# RUN FOR 3 MODELS\n# ============================================================\nresults = {}\n\nresults[\"CNN\"]       = get_top10_IG(\"CNN\",       CNN_CFG,     MODEL_PATHS[\"CNN\"])\nresults[\"CNN-Attn\"]  = get_top10_IG(\"CNN-Attn\",  ATTN_CFG,    MODEL_PATHS[\"CNN-Attn\"])\nresults[\"CNN-BiLSTM\"]= get_top10_IG(\"CNN-BiLSTM\",BI_LSTM_CFG, MODEL_PATHS[\"CNN-BiLSTM\"])\n\n# ============================================================\n# PRINT RESULTS EXACTLY LIKE ML VERSION\n# ============================================================\nfor m in [\"CNN\",\"CNN-Attn\",\"CNN-BiLSTM\"]:\n    print(f\"\\n========================\")\n    print(f\"Top-10 TF (Class 6) Motifs → {m}\")\n    print(\"========================\")\n    motifs,weights = results[m]\n    for motif,w in zip(motifs,weights):\n        print(f\"{motif}   |   score={w:.4f}\")\n\n# ============================================================\n# COMPARISON TABLE\n# ============================================================\ncompare_table = pd.DataFrame({\n    \"CNN\":       results[\"CNN\"][0],\n    \"CNN-Attn\":  results[\"CNN-Attn\"][0],\n    \"CNN-BiLSTM\":results[\"CNN-BiLSTM\"][0]\n})\n\nprint(\"\\n\\nCROSS-MODEL TOP-10 MOTIF COMPARISON TABLE (Human, TF):\")\nprint(compare_table)\n\n# ============================================================\n# CONSENSUS ANALYSIS\n# ============================================================\nCNN_set       = set(results[\"CNN\"][0])\nAT_set        = set(results[\"CNN-Attn\"][0])\nBI_set        = set(results[\"CNN-BiLSTM\"][0])\n\nstrict_consensus = CNN_set & AT_set & BI_set\nmajority_consensus = (CNN_set & AT_set) | (CNN_set & BI_set) | (AT_set & BI_set)\n\nprint(\"\\n========================\")\nprint(\"STRICT CONSENSUS (ALL 3 DL models):\")\nprint(\"========================\")\nprint(sorted(list(strict_consensus)) if strict_consensus else \"None\")\n\nprint(\"\\n========================\")\nprint(\"MAJORITY CONSENSUS (≥2 DL models):\")\nprint(\"========================\")\nprint(sorted(list(majority_consensus)) if majority_consensus else \"None\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:36:48.059260Z","iopub.execute_input":"2025-12-03T06:36:48.059820Z","iopub.status.idle":"2025-12-03T06:38:06.728243Z","shell.execute_reply.started":"2025-12-03T06:36:48.059794Z","shell.execute_reply":"2025-12-03T06:38:06.727451Z"}},"outputs":[{"name":"stdout","text":"\n\n============================\nMODEL: CNN\n============================\nTF samples in test set: 269\n\n\n============================\nMODEL: CNN-Attn\n============================\nTF samples in test set: 269\n\n\n============================\nMODEL: CNN-BiLSTM\n============================\nTF samples in test set: 269\n\n========================\nTop-10 TF (Class 6) Motifs → CNN\n========================\ncagcag   |   score=76.8405\nagcagc   |   score=53.1437\ngcagca   |   score=32.3086\naggagg   |   score=25.3584\nggagga   |   score=23.4207\nagcccc   |   score=22.3878\nccagca   |   score=21.2277\nccccgg   |   score=20.1202\ngcggcg   |   score=19.8683\nagcaga   |   score=19.0683\n\n========================\nTop-10 TF (Class 6) Motifs → CNN-Attn\n========================\ncagcag   |   score=171.9802\nagcagc   |   score=101.3025\nccagca   |   score=77.1736\ngcagca   |   score=67.2537\naggagg   |   score=58.4936\ncacaga   |   score=54.7885\ncggagg   |   score=44.4612\nagctca   |   score=40.4150\nctggaa   |   score=37.5330\ntggagg   |   score=35.8858\n\n========================\nTop-10 TF (Class 6) Motifs → CNN-BiLSTM\n========================\nagcagc   |   score=41.4212\natggcc   |   score=29.7714\ncagcag   |   score=23.7486\natggac   |   score=21.9047\ngcagca   |   score=21.3839\ntggagg   |   score=15.7186\natggcg   |   score=13.0852\nagaaga   |   score=12.0084\ngcccga   |   score=11.2745\naaagaa   |   score=10.9821\n\n\nCROSS-MODEL TOP-10 MOTIF COMPARISON TABLE (Human, TF):\n      CNN CNN-Attn CNN-BiLSTM\n0  cagcag   cagcag     agcagc\n1  agcagc   agcagc     atggcc\n2  gcagca   ccagca     cagcag\n3  aggagg   gcagca     atggac\n4  ggagga   aggagg     gcagca\n5  agcccc   cacaga     tggagg\n6  ccagca   cggagg     atggcg\n7  ccccgg   agctca     agaaga\n8  gcggcg   ctggaa     gcccga\n9  agcaga   tggagg     aaagaa\n\n========================\nSTRICT CONSENSUS (ALL 3 DL models):\n========================\n['agcagc', 'cagcag', 'gcagca']\n\n========================\nMAJORITY CONSENSUS (≥2 DL models):\n========================\n['agcagc', 'aggagg', 'cagcag', 'ccagca', 'gcagca', 'tggagg']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nfrom captum.attr import IntegratedGradients\nfrom sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\nfrom sklearn.model_selection import train_test_split\nimport re\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# =====================================================\n# LOAD COMBINED DATASET\n# =====================================================\nchimp = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/chimpanzee.txt\", sep=\"\\t\").dropna()\nhuman = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/human.txt\", sep=\"\\t\").dropna()\ndog   = pd.read_csv(\"/kaggle/input/dna-sequence-dataset/dog.txt\", sep=\"\\t\").dropna()\n\ncombined = pd.concat([chimp, human, dog], ignore_index=True)\ncombined.columns = [\"sequence\", \"class\"]\ncombined[\"label\"] = combined[\"class\"].astype(\"category\").cat.codes\n\nFUNCTIONAL_GROUPS = sorted(combined[\"label\"].unique())  # [0..6]\n\n# =====================================================\n# VOCAB RECONSTRUCTION (PERFECT MATCH)\n# =====================================================\nK = 6\nMAX_LEN = 300\n\ndef kmers(seq, k=K):\n    seq = seq.lower()\n    return [seq[i:i+k] for i in range(len(seq)-k+1)]\n\ndef rebuild_vocab(seqs, k=K):\n    all_k = []\n    for s in seqs:\n        all_k.extend(kmers(s, k))\n    # EXACT ordering used during training\n    return {km: idx+1 for idx,(km,_) in enumerate(Counter(all_k).most_common())}\n\nvocab = rebuild_vocab(combined[\"sequence\"].values)\nVOCAB_SIZE = len(vocab) + 1\nprint(\"Reconstructed vocab size:\", VOCAB_SIZE)\n\ndef encode(seq):\n    return [vocab[k] for k in kmers(seq) if k in vocab]\n\ndef pad(seqs):\n    out = np.zeros((len(seqs), MAX_LEN), dtype=np.int64)\n    for i, seq in enumerate(seqs):\n        s = seq[:MAX_LEN]\n        out[i, :len(s)] = s\n    return out\n\n# =====================================================\n# DATA SPLIT\n# =====================================================\nX_raw = combined[\"sequence\"].values\ny = combined[\"label\"].values\n\nX_enc = pad([encode(s) for s in X_raw])\n\nX_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(\n    X_enc, y, X_raw, test_size=0.2, stratify=y, random_state=42\n)\n\nNUM_CLASSES = len(np.unique(y))\n\n# =====================================================\n# DATASET CLASS\n# =====================================================\nclass SeqDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.long)\n        self.y = torch.tensor(y, dtype=torch.long)\n    def __len__(self): return len(self.X)\n    def __getitem__(self, i): return self.X[i], self.y[i]\n\ntest_loader = DataLoader(SeqDataset(X_test, y_test), batch_size=64)\n\n# =====================================================\n# DL MODELS — EXACT TRAINED CONFIGS\n# =====================================================\nclass CNN(nn.Module):\n    def __init__(self, vocab_size, nc, embed_dim=128, num_filters=256, kernel_sizes=(5,7,9)):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, k, padding=k//2) \n                                    for k in kernel_sizes])\n        self.fc = nn.Linear(num_filters * len(kernel_sizes), nc)\n\n    def forward(self, x):\n        x = self.embed(x).transpose(1,2)\n        h = [F.max_pool1d(F.relu(conv(x)), x.shape[2]).squeeze(2) for conv in self.convs]\n        return self.fc(torch.cat(h,1))\n\nclass CNNAttn(nn.Module):\n    def __init__(self, vocab_size, nc, embed_dim=128, conv_filters=128, conv_kernel=7, n_heads=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(embed_dim, conv_filters, conv_kernel, padding=conv_kernel//2)\n        self.proj = nn.Linear(conv_filters, embed_dim)\n        self.attn = nn.MultiheadAttention(embed_dim, n_heads, batch_first=True)\n        self.fc = nn.Linear(embed_dim, nc)\n\n    def forward(self,x):\n        x = self.embed(x)\n        x = F.relu(self.conv(x.transpose(1,2))).transpose(1,2)\n        x = self.proj(x)\n        a,_ = self.attn(x,x,x)\n        return self.fc(a.mean(1))\n\nclass CNNBiLSTM(nn.Module):\n    def __init__(self, vocab_size, nc, embed_dim=256, conv_filters=256, lstm_hidden=512):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(embed_dim, conv_filters, 7, padding=3)\n        self.lstm = nn.LSTM(conv_filters, lstm_hidden, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(lstm_hidden*2, nc)\n\n    def forward(self, x):\n        x = self.embed(x)\n        x = F.relu(self.conv(x.transpose(1,2))).transpose(1,2)\n        h,_ = self.lstm(x)\n        h,_ = torch.max(h,1)\n        return self.fc(h)\n\n# =====================================================\n# LOAD SAVED MODELS\n# =====================================================\nCNN_CFG = {\"embed_dim\":128, \"num_filters\":256, \"kernel_sizes\":(5,7,9)}\nATTN_CFG = {\"embed_dim\":128, \"conv_filters\":128, \"conv_kernel\":7, \"n_heads\":2}\nBI_CFG   = {'embed_dim': 128, 'conv_filters': 256, 'lstm_hidden': 256}\n\ncnn = CNN(VOCAB_SIZE, NUM_CLASSES, **CNN_CFG).to(DEVICE)\nattn = CNNAttn(VOCAB_SIZE, NUM_CLASSES, **ATTN_CFG).to(DEVICE)\nbilstm = CNNBiLSTM(VOCAB_SIZE, NUM_CLASSES, **BI_CFG).to(DEVICE)\n\ncnn.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/combined_kmer_CNN.pt\", map_location=DEVICE))\nattn.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/combined_kmer_CNN-Attention.pt\", map_location=DEVICE))\nbilstm.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/combined_kmer_CNN-BiLSTM.pt\", map_location=DEVICE))\n\nmodels = {\"CNN\": cnn, \"CNN-Attn\": attn, \"CNN-BiLSTM\": bilstm}\n\n# =====================================================\n# HELPER: FORWARD EMBEDDING PASS FOR IG\n# =====================================================\ndef forward_emb(model, emb):\n    if isinstance(model, CNN):\n        x = emb.transpose(1,2)\n        h = [F.max_pool1d(F.relu(c(x)), x.shape[2]).squeeze(2) for c in model.convs]\n        return model.fc(torch.cat(h,1))\n\n    elif isinstance(model, CNNAttn):\n        x = F.relu(model.conv(emb.transpose(1,2))).transpose(1,2)\n        x = model.proj(x)\n        a,_ = model.attn(x,x,x)\n        return model.fc(a.mean(1))\n\n    else:  # CNN-BiLSTM\n        x = F.relu(model.conv(emb.transpose(1,2))).transpose(1,2)\n        h,_ = model.lstm(x)\n        h,_ = torch.max(h,1)\n        return model.fc(h)\n\n# =====================================================\n# IG MOTIF EXTRACTION\n# =====================================================\ndef get_top10_IG(model, FG):\n    model.eval()\n\n    embed = model.embed\n    ig = IntegratedGradients(lambda emb: forward_emb(model, emb))\n\n    FG_indices = np.where(y_test == FG)[0]\n    if len(FG_indices) == 0: return [], []\n\n    attr_sum = Counter()\n\n    for idx in FG_indices[:200]:\n        x = torch.tensor(X_test[idx], dtype=torch.long, device=DEVICE).unsqueeze(0)\n        emb = embed(x)\n        baseline = torch.zeros_like(emb)\n\n        attr, _ = ig.attribute(\n    emb,\n    baselines=baseline,\n    target=int(FG),\n    return_convergence_delta=True\n)\n\n        attr = attr.squeeze(0).abs().sum(dim=1).detach().cpu()\n\n        km = kmers(X_raw_test[idx])\n        for score, kmer in zip(attr[:len(km)], km):\n            attr_sum[kmer] += float(score)\n\n    motifs, weights = zip(*attr_sum.most_common(10))\n    return list(motifs), list(weights)\n\n# =====================================================\n# MASKING (OPTION A)\n# =====================================================\ndef mask_sequences(raw_list, motifs):\n    masked = []\n    for seq in raw_list:\n        sx = seq.lower()\n        for m in motifs:\n            sx = re.sub(m, \"N\"*K, sx)\n        enc = encode(sx)\n        enc = enc[:MAX_LEN]\n        padded = enc + [0]*(MAX_LEN - len(enc))\n        masked.append(padded)\n    return np.array(masked, dtype=np.int64)\n\n# =====================================================\n# DL EVALUATION\n# =====================================================\ndef eval_dl(model, X, y):\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for i in range(0, len(X), 64):\n            xb = torch.tensor(X[i:i+64], dtype=torch.long, device=DEVICE)\n            logits = model(xb)\n            preds.extend(logits.argmax(1).cpu().numpy())\n    return {\n        \"acc\": accuracy_score(y, preds),\n        \"f1\": f1_score(y, preds, average=\"macro\"),\n        \"mcc\": matthews_corrcoef(y, preds)\n    }\n\n# =====================================================\n# MAIN LOOP — STAGE 3 DL XAI\n# =====================================================\nfor FG in FUNCTIONAL_GROUPS:\n    FG = int(FG)\n\n    print(\"\\n\" + \"=\"*85)\n    print(f\"FUNCTIONAL GROUP {FG} — DEEP LEARNING STAGE-3 XAI\")\n    print(\"=\"*85)\n\n    # ---- A: Extract motifs ----\n    top10 = {}\n    for name, model in models.items():\n        motifs, weights = get_top10_IG(model, FG)\n        top10[name] = motifs\n\n    print(\"\\nTop-10 motifs per DL model:\")\n    print(pd.DataFrame(top10))\n\n    # ---- B: Stability ----\n    def stab(A,B):\n        A,B=set(A),set(B)\n        inter = len(A&B)\n        union = len(A|B)\n        jac = inter/union if union>0 else 0\n        pct = inter/10\n        return inter, jac, pct*100\n\n    print(\"\\nStability (intersection, jaccard, overlap%):\")\n    for a,b in [(\"CNN\",\"CNN-Attn\"),(\"CNN\",\"CNN-BiLSTM\"),(\"CNN-Attn\",\"CNN-BiLSTM\")]:\n        inter, jac, pct = stab(top10[a], top10[b])\n        print(f\"{a}–{b}: inter={inter}, jaccard={jac:.3f}, overlap%={pct:.1f}\")\n\n    # ---- C: Baseline ----\n    baseline = {}\n    for name, model in models.items():\n        baseline[name] = eval_dl(model, X_test, y_test)\n\n    print(\"\\nBaseline performance:\")\n    print(pd.DataFrame(baseline).T)\n\n    # ---- D: Fidelity (masking) ----\n    fidelity = {}\n    for name, model in models.items():\n\n        masked_X = mask_sequences(X_raw_test, top10[name])\n        masked_eval = eval_dl(model, masked_X, y_test)\n\n        fidelity[name] = {\n            \"acc_drop\": baseline[name][\"acc\"] - masked_eval[\"acc\"],\n            \"f1_drop\": baseline[name][\"f1\"] - masked_eval[\"f1\"],\n            \"mcc_drop\": baseline[name][\"mcc\"] - masked_eval[\"mcc\"]\n        }\n\n    print(\"\\nFidelity drop after masking:\")\n    print(pd.DataFrame(fidelity).T)\n\n    # ---- E: Consensus ----\n    s1 = set(top10[\"CNN\"])\n    s2 = set(top10[\"CNN-Attn\"])\n    s3 = set(top10[\"CNN-BiLSTM\"])\n\n    strict  = s1 & s2 & s3\n    majority = (s1&s2)|(s1&s3)|(s2&s3)\n\n    print(\"\\nStrict consensus:\", sorted(list(strict)) if strict else \"None\")\n    print(\"Majority consensus:\", sorted(list(majority)) if majority else \"None\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:53:06.554058Z","iopub.execute_input":"2025-12-03T06:53:06.554341Z","iopub.status.idle":"2025-12-03T06:58:24.241384Z","shell.execute_reply.started":"2025-12-03T06:53:06.554320Z","shell.execute_reply":"2025-12-03T06:58:24.240738Z"}},"outputs":[{"name":"stdout","text":"Reconstructed vocab size: 4557\n\n=====================================================================================\nFUNCTIONAL GROUP 0 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  cctgct   cttctg     ctgctg\n1  cttctg   gtcttc     cctgct\n2  ctcttc   tcttct     tcctgg\n3  ctgctg   ttctgg     ctcttc\n4  ctgctc   ctgcct     atgact\n5  gctgct   tgtctt     ctgctc\n6  tgctct   ttctgc     tgctgc\n7  tcttct   ctgctg     cttctg\n8  ttctgg   acttct     atggag\n9  tgctgc   tctgcc     ttcctg\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=4, jaccard=0.250, overlap%=40.0\nCNN–CNN-BiLSTM: inter=6, jaccard=0.429, overlap%=60.0\nCNN-Attn–CNN-BiLSTM: inter=2, jaccard=0.111, overlap%=20.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.002179  0.001911  0.002645\nCNN-Attn    0.031227  0.034205  0.038307\nCNN-BiLSTM  0.002905  0.002416  0.003512\n\nStrict consensus: ['ctgctg', 'cttctg']\nMajority consensus: ['cctgct', 'ctcttc', 'ctgctc', 'ctgctg', 'cttctg', 'tcttct', 'tgctgc', 'ttctgg']\n\n=====================================================================================\nFUNCTIONAL GROUP 1 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  gctgct   tgctgc     atgggc\n1  ccatcc   ctgctg     atggga\n2  ctgctg   ttactg     gctgct\n3  tgctgc   tactgc     ctgctg\n4  gatgct   tttact     tgggct\n5  accatc   actgct     tgctgc\n6  atgctg   ctttac     gggacc\n7  tgctga   tcttta     gggctg\n8  cccagc   tgtgtg     tgggac\n9  tgcagg   gctgtg     ggacca\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=2, jaccard=0.111, overlap%=20.0\nCNN–CNN-BiLSTM: inter=3, jaccard=0.176, overlap%=30.0\nCNN-Attn–CNN-BiLSTM: inter=2, jaccard=0.111, overlap%=20.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.002905  0.000434  0.003525\nCNN-Attn    0.018882  0.020497  0.023076\nCNN-BiLSTM  0.002179  0.001417  0.002650\n\nStrict consensus: ['ctgctg', 'tgctgc']\nMajority consensus: ['ctgctg', 'gctgct', 'tgctgc']\n\n=====================================================================================\nFUNCTIONAL GROUP 2 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  ctgctg   tgcctg     gctgct\n1  tgctgc   ccttca     tgctgc\n2  cttcag   ctcttt     ctgctg\n3  gctgct   gcctgc     atggtg\n4  ccttca   ctgcct     ggaggc\n5  tgagga   gcctct     gaggcc\n6  cccaag   gagcag     gcccct\n7  aagaag   cagcag     ggctgc\n8  tcagaa   ttgcct     ggcccc\n9  agccag   tctttc     atggag\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=1, jaccard=0.053, overlap%=10.0\nCNN–CNN-BiLSTM: inter=3, jaccard=0.176, overlap%=30.0\nCNN-Attn–CNN-BiLSTM: inter=0, jaccard=0.000, overlap%=0.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.004357  0.003397  0.005286\nCNN-Attn    0.031227  0.035955  0.037982\nCNN-BiLSTM  0.000726  0.001290  0.000890\n\nStrict consensus: None\nMajority consensus: ['ccttca', 'ctgctg', 'gctgct', 'tgctgc']\n\n=====================================================================================\nFUNCTIONAL GROUP 3 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  cccagc   cgcctg     atgccc\n1  ggagct   cagcag     tggcag\n2  ttctgg   tgctca     atggca\n3  caggag   gcctgc     atggcg\n4  ctggag   ttctgg     tggcgg\n5  ctgctg   tgggtg     cccagc\n6  gagctg   agctgg     atgttg\n7  gctgga   ctctgg     ggcggc\n8  gcagcc   cagctg     tgtggc\n9  agaagc   gagctg     tgccca\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=2, jaccard=0.111, overlap%=20.0\nCNN–CNN-BiLSTM: inter=1, jaccard=0.053, overlap%=10.0\nCNN-Attn–CNN-BiLSTM: inter=0, jaccard=0.000, overlap%=0.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.003631  0.002777  0.004388\nCNN-Attn    0.054466  0.053445  0.065911\nCNN-BiLSTM  0.001452  0.001209  0.001783\n\nStrict consensus: None\nMajority consensus: ['cccagc', 'gagctg', 'ttctgg']\n\n=====================================================================================\nFUNCTIONAL GROUP 4 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  ctggcc   ctggtg     tcctgg\n1  tcctgg   cccggc     atgctg\n2  gctgct   ggtggc     atggag\n3  ttctgg   gcccca     ctggcc\n4  ctgctg   ccggct     tgctgc\n5  cctggc   ccccaa     cctggc\n6  gccgcc   atggtt     ctgcaa\n7  cgccgc   cggccc     tggagg\n8  ctggag   tggtgt     atgaag\n9  ggtggc   gcccgg     gctgca\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=1, jaccard=0.053, overlap%=10.0\nCNN–CNN-BiLSTM: inter=3, jaccard=0.176, overlap%=30.0\nCNN-Attn–CNN-BiLSTM: inter=0, jaccard=0.000, overlap%=0.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.000000  0.000528  0.000005\nCNN-Attn    0.053014  0.054351  0.064893\nCNN-BiLSTM  0.002905  0.003010  0.003532\n\nStrict consensus: None\nMajority consensus: ['cctggc', 'ctggcc', 'ggtggc', 'tcctgg']\n\n=====================================================================================\nFUNCTIONAL GROUP 5 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  gctgct   cagcaa     ctgctg\n1  ctgctg   ctacat     tgctgc\n2  tgctgc   tggact     gctgct\n3  gggaga   actaca     aggagg\n4  ggagaa   ccccac     ggagga\n5  tggagg   gtggac     ggagaa\n6  ggagga   aggtgt     tcctgg\n7  tcctgg   gcagca     agctgc\n8  agaagg   gcaatg     gaggag\n9  gagctg   cccacc     ggagcc\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=0, jaccard=0.000, overlap%=0.0\nCNN–CNN-BiLSTM: inter=6, jaccard=0.429, overlap%=60.0\nCNN-Attn–CNN-BiLSTM: inter=0, jaccard=0.000, overlap%=0.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.006536  0.005922  0.007939\nCNN-Attn    0.020334  0.020857  0.024769\nCNN-BiLSTM  0.002179  0.002121  0.002642\n\nStrict consensus: None\nMajority consensus: ['ctgctg', 'gctgct', 'ggagaa', 'ggagga', 'tcctgg', 'tgctgc']\n\n=====================================================================================\nFUNCTIONAL GROUP 6 — DEEP LEARNING STAGE-3 XAI\n=====================================================================================\n\nTop-10 motifs per DL model:\n      CNN CNN-Attn CNN-BiLSTM\n0  cagcag   cagcag     cagcag\n1  agcagc   gcagca     agcagc\n2  gcagca   ccagca     gcagca\n3  aggagg   aagctg     ccagca\n4  ggagga   ccctcc     atgtcc\n5  agaaga   agcagc     aggagg\n6  ggcggc   cccaac     tgctgc\n7  aagatg   ccccaa     aagctg\n8  accagc   gcccca     atggag\n9  gcggcg   caagct     atggcc\n\nStability (intersection, jaccard, overlap%):\nCNN–CNN-Attn: inter=3, jaccard=0.176, overlap%=30.0\nCNN–CNN-BiLSTM: inter=4, jaccard=0.250, overlap%=40.0\nCNN-Attn–CNN-BiLSTM: inter=5, jaccard=0.333, overlap%=50.0\n\nBaseline performance:\n                 acc        f1       mcc\nCNN         0.986928  0.984707  0.984069\nCNN-Attn    0.972404  0.971100  0.966287\nCNN-BiLSTM  0.988381  0.989162  0.985812\n\nFidelity drop after masking:\n            acc_drop   f1_drop  mcc_drop\nCNN         0.008715  0.005554  0.010494\nCNN-Attn    0.043573  0.042179  0.052522\nCNN-BiLSTM  0.001452  0.001531  0.001783\n\nStrict consensus: ['agcagc', 'cagcag', 'gcagca']\nMajority consensus: ['aagctg', 'agcagc', 'aggagg', 'cagcag', 'ccagca', 'gcagca']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from collections import Counter\n\nK = 6\n\ndef kmers(seq, k=K):\n    return [seq[i:i+k].lower() for i in range(len(seq)-k+1)]\n\ndef build_vocab(seqs):\n    all_k = []\n    for s in seqs:\n        all_k.extend(kmers(s, K))\n    # EXACT original rule: most_common() preserves frequency order\n    most_common = Counter(all_k).most_common()\n    vocab = {kmer: i+1 for i, (kmer, _) in enumerate(most_common)}\n    return vocab\n\ndef encode_kmer(seq, vocab):\n    return [vocab[k] for k in kmers(seq, K) if k in vocab]\n\ndef pad_kmer(encoded_list, MAX_LEN=300):\n    out = np.zeros((len(encoded_list), MAX_LEN), dtype=np.int64)\n    for i, s in enumerate(encoded_list):\n        L = min(len(s), MAX_LEN)\n        out[i, :L] = s[:L]\n    return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T03:58:57.257550Z","iopub.execute_input":"2025-12-03T03:58:57.257904Z","iopub.status.idle":"2025-12-03T03:58:57.266082Z","shell.execute_reply.started":"2025-12-03T03:58:57.257877Z","shell.execute_reply":"2025-12-03T03:58:57.265059Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"X_raw = df[\"sequence\"].values\ny     = df[\"label\"].values\n\nvocab = build_vocab(X_raw)\nX = np.stack([encode_kmer(s, vocab) for s in X_raw])\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(\n    X, y, X_raw, test_size=0.2, stratify=y, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:11:41.960039Z","iopub.execute_input":"2025-12-02T14:11:41.960630Z","iopub.status.idle":"2025-12-02T14:11:45.146860Z","shell.execute_reply.started":"2025-12-02T14:11:41.960602Z","shell.execute_reply":"2025-12-02T14:11:45.145900Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_160/3206025386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_kmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"],"ename":"ValueError","evalue":"all input arrays must have the same shape","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, vocab_size, num_classes=7):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, 128)\n        self.convs = nn.ModuleList([\n            nn.Conv1d(128, 256, 5),\n            nn.Conv1d(128, 256, 7),\n            nn.Conv1d(128, 256, 9)\n        ])\n        self.fc = nn.Linear(256*3, num_classes)\n\n    def forward(self, x):\n        x = self.embed(x).transpose(1,2)\n        h = [torch.max(conv(x), dim=2)[0] for conv in self.convs]\n        h = torch.cat(h, dim=1)\n        return self.fc(h)\n        \nclass CNNAttention(nn.Module):\n    def __init__(self, vocab_size, num_classes=7,\n                 embed_dim=256, conv_filters=256,\n                 conv_kernel=15, n_heads=4, dropout=0.4):\n        super().__init__()\n        \n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        \n        self.conv = nn.Conv1d(embed_dim,\n                              conv_filters,\n                              conv_kernel,\n                              padding=conv_kernel // 2)\n        \n        self.proj = nn.Linear(conv_filters, embed_dim)\n        \n        self.attn = nn.MultiheadAttention(embed_dim,\n                                          n_heads,\n                                          batch_first=True)\n        \n        self.drop = nn.Dropout(dropout)\n        self.fc   = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        x = self.embed(x)                             # (B, T, E)\n        x = F.relu(self.conv(x.transpose(1,2)))       # (B, C, T)\n        x = self.proj(x.transpose(1,2))               # (B, T, E)\n        a, _ = self.attn(x, x, x)                     # (B, T, E)\n        h = a.mean(1)                                 # (B, E)\n        return self.fc(self.drop(h))                  # (B, num_classes)\n\nclass CNNBiLSTM(nn.Module):\n    def __init__(self, vocab_size, num_classes=7):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, 128)\n        self.conv  = nn.Conv1d(128, 256, 7)\n        self.lstm  = nn.LSTM(256, 256, batch_first=True, bidirectional=True)\n        self.fc    = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        e = self.embed(x).transpose(1,2)\n        c = self.conv(e).transpose(1,2)\n        h,_ = self.lstm(c)\n        h = h.mean(dim=1)\n        return self.fc(h)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:11:46.564669Z","iopub.execute_input":"2025-12-02T14:11:46.564918Z","iopub.status.idle":"2025-12-02T14:11:46.575195Z","shell.execute_reply.started":"2025-12-02T14:11:46.564901Z","shell.execute_reply":"2025-12-02T14:11:46.574461Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nvocab_size = len(vocab)\n\ncnn = CNN(vocab_size).to(DEVICE)\ncnn.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN.pt\", map_location=DEVICE))\n\nattn = CNNAttention(vocab_size).to(DEVICE)\nattn.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN-Attention.pt\", map_location=DEVICE))\n\nbilstm = CNNBiLSTM(vocab_size).to(DEVICE)\nbilstm.load_state_dict(torch.load(\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN-BiLSTM.pt\", map_location=DEVICE))\n\ncnn.eval(); attn.eval(); bilstm.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:11:46.931601Z","iopub.execute_input":"2025-12-02T14:11:46.932330Z","iopub.status.idle":"2025-12-02T14:11:46.987601Z","shell.execute_reply.started":"2025-12-02T14:11:46.932300Z","shell.execute_reply":"2025-12-02T14:11:46.986719Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_160/3983017187.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/dna-saved-models/pytorch/default/1/DL Models/DL Models/human_kmer_CNN.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tsize mismatch for embed.weight: copying a param with shape torch.Size([4470, 128]) from checkpoint, the shape in current model is torch.Size([4469, 128])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for CNN:\n\tsize mismatch for embed.weight: copying a param with shape torch.Size([4470, 128]) from checkpoint, the shape in current model is torch.Size([4469, 128]).","output_type":"error"}],"execution_count":37},{"cell_type":"code","source":"TARGET_CLASS_DL = 3   # Synthetase\n\nfrom captum.attr import GradientShap\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom captum.attr import GradientShap\n\n\ndef top10_gradshap_global(model, X, raw_sequences,\n                          class_id=TARGET_CLASS_DL,\n                          k=6, topk=10,\n                          max_samples=40):\n\n    DEVICE = next(model.parameters()).device\n    model.eval()\n\n    # Disable cuDNN to allow LSTM backward\n    torch.backends.cudnn.enabled = False\n\n    Xt = torch.tensor(X, dtype=torch.long).to(DEVICE)\n\n    # ----------------------------\n    # Forward starting at embedding\n    # ----------------------------\n    def forward_from_emb(e):\n        # CNN\n        if hasattr(model, \"convs\"):\n            x = e.transpose(1,2)\n            h = [torch.max(conv(x), dim=2)[0] for conv in model.convs]\n            return model.fc(torch.cat(h, dim=1))\n\n        # CNN-Attention\n        if hasattr(model, \"attn\"):\n            c = F.relu(model.conv(e.transpose(1,2))).transpose(1,2)\n            p = model.proj(c)\n            a,_ = model.attn(p,p,p)\n            return model.fc(model.drop(a.mean(1)))\n\n        # CNN-BiLSTM\n        if hasattr(model, \"lstm\"):\n            c = F.relu(model.conv(e.transpose(1,2))).transpose(1,2)\n            h,_ = model.lstm(c)\n            return model.fc(h.mean(1))\n\n\n    gs = GradientShap(forward_from_emb)\n\n    # global 300-token importance\n    global_token_scores = np.zeros(300)\n\n    N = min(len(Xt), max_samples)\n\n    for i in range(N):\n\n        xi = Xt[i:i+1]  # (1, 300)\n        emb = model.embed(xi)\n        emb = emb.detach().clone().requires_grad_(True)\n\n        baseline = torch.zeros_like(emb)  # zeros baseline\n\n        # GradientShap for this one sequence\n        attr = gs.attribute(\n            emb,\n            baselines=baseline,\n            target=class_id,\n            n_samples=12,\n            stdevs=0.01\n        )  # (1, 300, E)\n\n        token_attr = attr.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n        global_token_scores += token_attr\n\n    global_token_scores /= N   # mean over samples\n\n    # Re-enable cuDNN\n    torch.backends.cudnn.enabled = True\n\n    # ----------------------------\n    # Motif aggregation\n    # ----------------------------\n    motif_scores = {}\n\n    for seq in raw_sequences[:N]:\n        seq = seq.lower()\n        L = len(seq)\n        for i in range(L - k + 1):\n            km = seq[i:i+k]\n            start = max(0, min(i, 300-k))\n            end   = max(0, min(i+k, 300))\n            motif_scores[km] = motif_scores.get(km, 0) + global_token_scores[start:end].mean()\n\n    sorted_motifs = sorted(motif_scores.items(), key=lambda x: x[1], reverse=True)\n    return [m for m,_ in sorted_motifs[:topk]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:03:26.592738Z","iopub.execute_input":"2025-12-02T14:03:26.593059Z","iopub.status.idle":"2025-12-02T14:03:26.604713Z","shell.execute_reply.started":"2025-12-02T14:03:26.593039Z","shell.execute_reply":"2025-12-02T14:03:26.603944Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"motifs_cnn  = top10_gradshap_global(cnn,   X_test, X_raw_test)\nmotifs_attn = top10_gradshap_global(attn,  X_test, X_raw_test)\nmotifs_bi   = top10_gradshap_global(bilstm, X_test, X_raw_test)\n\nprint(\"CNN motifs:\", motifs_cnn)\nprint(\"CNN-Attention motifs:\", motifs_attn)\nprint(\"CNN-BiLSTM motifs:\", motifs_bi)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:03:28.270995Z","iopub.execute_input":"2025-12-02T14:03:28.271550Z","iopub.status.idle":"2025-12-02T14:03:34.092318Z","shell.execute_reply.started":"2025-12-02T14:03:28.271524Z","shell.execute_reply":"2025-12-02T14:03:34.091610Z"}},"outputs":[{"name":"stdout","text":"CNN motifs: ['ggcctg', 'agtgga', 'cagcgg', 'gtggag', 'ggagtg', 'tgggag', 'cctgaa', 'cacgca', 'ctgccg', 'gcgggg']\nCNN-Attention motifs: ['ctggag', 'gaagaa', 'ggcctg', 'ctgaag', 'tgaaga', 'ggagcc', 'tgctga', 'agaaga', 'gctgga', 'ccctgg']\nCNN-BiLSTM motifs: ['ctgctg', 'ggcggc', 'gaggag', 'cagcag', 'gcagcc', 'ctggac', 'tgaaga', 'gctgct', 'gctgag', 'ggagga']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def mask_motifs(seq, motifs):\n    seq = seq.lower()\n    for m in motifs:\n        seq = seq.replace(m, \"NNNNNN\")\n    return seq\n\ndef encode_masked(seq, vocab):\n    return encode_kmer(seq, vocab)\n    \nfrom sklearn.metrics import accuracy_score, matthews_corrcoef\nimport numpy as np\n\ndef eval_dl(model, raw_sequences, true_labels, motifs=None, batch_size=16):\n    \"\"\"\n    Memory-safe evaluation for deep learning models.\n    Uses batched forward passes to avoid GPU OOM.\n    Requires global 'encode_kmer' and 'vocab'.\n    \"\"\"\n\n    DEVICE = next(model.parameters()).device\n    model.eval()\n\n    # 1. Mask motifs (if any)\n    if motifs is not None:\n        raw_masked = []\n        for seq in raw_sequences:\n            s = seq.lower()\n            for m in motifs:\n                s = s.replace(m, \"N\"*len(m))\n            raw_masked.append(s)\n    else:\n        raw_masked = raw_sequences\n\n    # 2. Encode sequences using existing vocab\n    X_masked = np.stack([encode_kmer(s, vocab) for s in raw_masked])\n    Xt = torch.tensor(X_masked, dtype=torch.long).to(DEVICE)\n\n    # 3. Batched prediction\n    preds = []\n    with torch.no_grad():\n        for i in range(0, len(Xt), batch_size):\n            batch = Xt[i:i+batch_size]\n            out = model(batch).argmax(dim=1).cpu().numpy()\n            preds.append(out)\n\n    preds = np.concatenate(preds)\n\n    # 4. Metrics\n    acc = accuracy_score(true_labels, preds)\n    mcc = matthews_corrcoef(true_labels, preds)\n\n    return acc, mcc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:06:04.244453Z","iopub.execute_input":"2025-12-02T14:06:04.244989Z","iopub.status.idle":"2025-12-02T14:06:04.251842Z","shell.execute_reply.started":"2025-12-02T14:06:04.244965Z","shell.execute_reply":"2025-12-02T14:06:04.251140Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"orig_cnn  = eval_dl(cnn,   X_raw_test, y_test)\nmask_cnn  = eval_dl(cnn,   X_raw_test, y_test, motifs_cnn)\n\norig_attn = eval_dl(attn,  X_raw_test, y_test)\nmask_attn = eval_dl(attn,  X_raw_test, y_test, motifs_attn)\n\norig_bi   = eval_dl(bilstm, X_raw_test, y_test)\nmask_bi   = eval_dl(bilstm, X_raw_test, y_test, motifs_bi)\nprint(\"\\n=== CNN FIDELITY (Top-10 Motifs) ===\")\nprint(\"Original ACC:\", orig_cnn[0], \"Masked ACC:\", mask_cnn[0], \"ΔAcc =\", orig_cnn[0]-mask_cnn[0])\nprint(\"Original MCC:\", orig_cnn[1], \"Masked MCC:\", mask_cnn[1], \"ΔMCC =\", orig_cnn[1]-mask_cnn[1])\n\nprint(\"\\n=== CNN-Attention FIDELITY (Top-10 Motifs) ===\")\nprint(\"Original ACC:\", orig_attn[0], \"Masked ACC:\", mask_attn[0], \"ΔAcc =\", orig_attn[0]-mask_attn[0])\nprint(\"Original MCC:\", orig_attn[1], \"Masked MCC:\", mask_attn[1], \"ΔMCC =\", orig_attn[1]-mask_attn[1])\n\nprint(\"\\n=== CNN-BiLSTM FIDELITY (Top-10 Motifs) ===\")\nprint(\"Original ACC:\", orig_bi[0], \"Masked ACC:\", mask_bi[0], \"ΔAcc =\", orig_bi[0]-mask_bi[0])\nprint(\"Original MCC:\", orig_bi[1], \"Masked MCC:\", mask_bi[1], \"ΔMCC =\", orig_bi[1]-mask_bi[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:06:06.936787Z","iopub.execute_input":"2025-12-02T14:06:06.937055Z","iopub.status.idle":"2025-12-02T14:06:09.835291Z","shell.execute_reply.started":"2025-12-02T14:06:06.937033Z","shell.execute_reply":"2025-12-02T14:06:09.834667Z"}},"outputs":[{"name":"stdout","text":"\n=== CNN FIDELITY (Top-10 Motifs) ===\nOriginal ACC: 0.20205479452054795 Masked ACC: 0.19863013698630136 ΔAcc = 0.003424657534246589\nOriginal MCC: 0.01483197098682229 Masked MCC: 0.0011968601949607792 ΔMCC = 0.013635110791861511\n\n=== CNN-Attention FIDELITY (Top-10 Motifs) ===\nOriginal ACC: 0.1815068493150685 Masked ACC: 0.1780821917808219 ΔAcc = 0.003424657534246589\nOriginal MCC: -0.0023007418133361816 Masked MCC: -0.009135370634063462 ΔMCC = 0.00683462882072728\n\n=== CNN-BiLSTM FIDELITY (Top-10 Motifs) ===\nOriginal ACC: 0.23401826484018265 Masked ACC: 0.1769406392694064 ΔAcc = 0.05707762557077625\nOriginal MCC: -0.005219771470780839 Masked MCC: -0.028518811129079384 ΔMCC = 0.023299039658298545\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}